% the abstract
\begin{abstractzh}
    即席视频检索在多媒体检索领域里是一个十分重要但是很有挑战的一个问题。不同于之前基于概念建模的方法，我提出了一个完全基于深度学习的方法来对查询语句的表示进行建模。该方法不需要显式的概念建模、匹配和选择。我的方法是以W2VV++为基础了，W2VV++方法是一个用于图像文本匹配模型Word2VisualVec(W2VV)模型的改进版。W2VV++是对W2VV的句子编码策略改进和使用improved triplet ranking loss的损失函数替代原来的均方差损失函数。通过这些简单但有效的改进，W2VV++的效果有了很大的提高。我们通过参加TRECVID 2018 AVS任务并且通过在TRECVID 2016和2017数据上的实验，我们最好的模型以总体infAP为0.157的性能，是最好的模。
\end{abstractzh}
