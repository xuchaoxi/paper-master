\chapter{绪论}
%\section{安装\LaTeX{} }
%\subsection{Mac OS X}
%\begin{figure}[htbp]
%\centering\includegraphics[width=5cm,height=1.32cm]{figures/Logo_2.pdf}
%\caption[示意图]{用LaTeX画图}
%\end{figure}

\section{研究背景与意义}
随着移动互联网的快速发展，人们可以随时随地通过智能设备上的应用创建和分享各种不同模态的多媒体数据，如文本、图像、视频等。其中视频
数据具有更丰富的信息，受到了更多用户的青睐，据《第44次中国互联网络发展状况统计报告》~\footnote{http://www.cac.gov.cn/2019-08/30/c\_1124938750.htm}显示，截至2019年6月，我国的网络视频用户规模
达7.59亿，占网民整体的88.8\%，其中短视频用户规模为6.48亿，占网民整体的75.8\%。各种短视频的智能设备应用也是呈井喷式的发展，如抖音、
快手等应用，用户可以通过这些应用创建和分享一分钟以内的短视频，据《2019年抖音数据报告》~\footnote{https://weibo.com/ttarticle/p/show?id=2309404457716281114897}显示，截至2020年1月5日，抖音日活跃用户数已经超过4亿，而根据快手发布的《2019快手内容报告》~\footnote{http://www.chinanews.com/business/2020/02-22/9100846.shtml}
显示，2019年有2.5亿用户通过快手平台发布作品，平台内有近200亿条的海量视频数据。在如此庞大的并且还在快速增长的视频数据里，
如何高效和精确地检索出用户需要或者感兴趣的视频是一个具有很大挑战并且具有应用价值的问题，是多媒体检索领域内的热点问题~\cite{hong2017,geetha2008a,hu2011a,peng2018an}。

即席视频检索检索(Ad-hoc Video Search, AVS)是指用户根据自己的需求以句子的形式来查询未经标注的视频,例如“一个有胡子的男人对着麦克风讲话或唱歌”~\cite{awad2016trecvid}。这和经典的基于内容的视频检索~\cite{yu2015content}不同，基于内容的视频检索是以一个图像或者视频片段
作为查询，从候选的视频数据中检索出与该查询内容相同或者相似的视频。这种视频检索方式在实际应用中有很大的局限性，因为用户通常不具有
能够表达其查询需求的图片或者视频，而以句子的形式表达用户需求则是一种更加直接方便的方式，例如用户希望检索出“一个男人在唱歌”这样场景的视频，而其并没有这样的样例视频，则其不能通过这种基于视频内容的视频检索技术进行检索，因此用户会更加倾向于使用句子的形式作为查询来检索想要的视频。即席视频检索也不同于长期研究的基于概念的视频检索技术~\cite{snoekcees2009concept}，这种检索技术的和核心是从视频中
检测出某些特定的概念，例如视频中出现的人或者物体，然后对查询句子提取关键词，利用查询关键词与检测出的概念进行匹配，这种检索技术需要
先定义一个概念集，然后检测视频中出现的概念，因此检索效果受限于概念的选择并且这种技术对查询句子的语义也没有进行建模分析。而本文研究
的即席视频检索是解决用户以一种模态的多媒体对象（文本）作为查询输入，检索出与查询语义上相同或相近的另一种模态的多媒体对象（视频），
这本质是也是一直被广泛关注的跨模态检索技术~\cite{rasiwasia2010a,feng2014cross,pereira2014on,suris2018cross,mithun2018learning}。
即席视频检索的核心是计算查询文本与候选视频在语义上的相关度，然后根据该相关度对候选视频进行排序，从而从候选视频中选出用户期望的视频，图~\ref{}展示了即席视频检索的大致流程。由于查询文本与视频是两种不同的模态，它们在底层表示上是异构的，即文本是由一序列的单词排列组成，而视频是由一序列图像组成并且伴随着音频，这也通常被称为“异构鸿沟”，因此这两种数据是不能直接进行比较或者计算相关度的。这两种
媒体数据的异构性和不可比性，使得即席视频检索是一个非常具有挑战性的研究任务。得益于美国国家标准与技术研究院（National Institute of Standards and Technology, NIST）举行的视频检索国际权威评测TRECVID AVS，提供的大量的测试数据集合、统一的评价标准，吸引了来自包括卡内基梅隆大学、弗吉尼亚大学、香港中文大学、早稻田大学等全球各地的优秀学者参与评测，推动了即席视频检索技术的发展~\cite{awad2016trecvid,awad2017trecvid,awad2018trecvid,awad2019trecvid}。如表格\ref{tab:method-diffs}所示，最近四年的研究方法都是基于公共空间学习的方法，这种方法为文本和视频学习一个公共空间，并将这两种模态的数据投影到公共空间进行表示，使得这两种数据的相关度可以在这个公共空间通过直接计算距离进行衡量，
这种方法有三个关键的模块，即文本表示、视频表示和公共空间，这三个模块的好坏与检索算法的效果有直接的关系，本文将关注对文本表示和公共空间这两个模块的改进，而视频表示则采用简单但有效的通过预训练的卷积神经网络(ResNeXt-101, ResNet-152)提取的视觉特征~\cite{li2018renmin,li2019renmin}。

%随着深度学习的提出~\cite{hinton2006a}，
在ImageNet图像识别大赛中~\cite{deng2009imagenet}，Hinton组在文献~\cite{krizhevsky2012imagenet}提出的深度卷积网络Alexnet把图像识别错误率从原来的25\%提升到15\%，极大地推动了深度学习模型的发展，而后

这在多媒体检索领域里是一个非常重要但又十分有挑战的问题,因为视频和文本这两个不同的模态存在语义鸿沟。

深度学习在图像分类领域的巨大发展，也有越来越多的深度学习模型在视频检索上进行尝试。


随着网络时代的发展,越来越多的视频应用出现,如 Youtube、爱奇艺、抖音等,用户可以随意上传短视频甚至电影,视频数据呈爆炸性的增长,其中一个重要的需求就是从海量的视频数据里精确地检索到用户需要的视频。通常情况下,用户没有要查找的视频样例,只能通过文本的形式来表达其需求。因此,研究以文本的形式检索视频,提高视频检索的准确率具有深远的理论意义和实践意义。


\section{本文研究内容}
随着大数据时代的进一步发展,数字化与智能化进程不断加速,新时代的
大数据呈现出新的特点与挑战
\section{论文结构安排}
随着大数据时代的进一步发展,数字化与智能化进程不断加速,新时代的
大数据呈现出新的特点与挑战

